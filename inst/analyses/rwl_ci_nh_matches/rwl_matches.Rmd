---
title: "Comparison of Children with Cochlear Implants and Matched Normal Hearing Peers on Four-Image Word Recognition Task"
author: "Tristan Mahr"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE, results = 'hide'}
library("knitr")
opts_chunk$set(
  collapse = TRUE, 
  comment = "#>", 
  message = FALSE,
  fig.width = 8,
  fig.height = 6,
  dpi = 300,
  out.width = "80%")

wd <- rprojroot::find_rstudio_root_file()
opts_knit$set(root.dir = wd)
```


## The Request

> I also wanted to ask you if you would have the time to help me get the data
> ready for the analysis of the CI data for the RWL task. Here's what I've done 
> so far:
>  
> 1. Put together the CI particpants
>   a. Omitted those tested before 1/15 (2 longitudinal participants)
>   b. Omitted those with more than 50% missing data across two blocks. I did 
>      include participants who had only 1 block with a low percentage of 
>      missing data.
> 2. Matched these to NH participants.
>   a. Group matched for age, maternal education, sex.
>   b. Group matched for number of test visits (the same number of participants 
>      in each group have 1 visit, 2 visits [1 year apart], 3 visits [1 year 
>      apart]).
>   c. Made sure that none of the NH matches have excessive missing data or were 
>      tested before 1/15.
> 
>  Could you do the following for me:
> 
>  1. Make a data frame that has the RWL eye-tracking data along with the 
>     usual subject-level information of interest (PPVT_GSV [if available], 
>     EVT_GSV, age, medu, GFTA [if available]).
>  2. Exclude blocks with more than 50% missing data and trials with more 
>     than 50% missing data.
>  3. Plot the data for the two groups (looks to the four images) for the time 
>     frame 300 to 1800 ms?
 
Load in the list of participants.

```{r}
library(dplyr)
library(L2TDatabase)

# Work relative to RStudio project
wd <- rprojroot::find_rstudio_root_file()
dir_here <- file.path(wd, "inst", "analyses", "rwl_ci_nh_matches")
cnf_file <- file.path(wd, "inst", "l2t_db.cnf")

# Load in the matches
df_kids <- file.path(dir_here, "ci_matches.csv") %>% 
  readr::read_csv(col_types = "ccic") %>% 
  print()
```

We need to get scores from the following studies.

```{r}
unique(df_kids$Study)
```

We have queries that combine the various scores together for each study in the 
main database. They have the pattern `Scores_[study-name]`. Download them all,
combine and select the requested columns.

```{r, warning = FALSE}
l2t_main <- l2t_connect(cnf_file, "l2t")
query_names <- paste0("Scores_", unique(df_kids$Study))

df_scores <- query_names %>% 
  # Download the each study's query
  lapply(function(tbl_name) tbl(l2t_main, tbl_name)) %>% 
  lapply(collect) %>% 
  # Combine into a single data-frame
  bind_rows() %>% 
  select(Study, ShortResearchID = ResearchID, 
         Female, AAE, LateTalker, CImplant, 
         Maternal_Education, Maternal_Education_Level, 
         EVT_Age, EVT_Raw, EVT_GSV, EVT_Standard,
         PPVT_Age, PPVT_Raw, PPVT_GSV, PPVT_Standard, 
         GFTA_Age:GFTA_Standard)

# Add the scores to the participants for analysis.
df_kids <- inner_join(df_kids, df_scores)
df_kids
```

We can confirm adequate matching.

```{r}
df_kids %>% 
  group_by(Group) %>% 
  summarise(
    N = n(),
    CI = sum(CImplant),
    N_Female = sum(Female),
    N_Male = sum(Female == 0),
    N_EVT = sum(!is.na(EVT_Age)),
    EVT_Age = mean(EVT_Age, na.rm = TRUE),
    N_PPVT = sum(!is.na(PPVT_Age)),
    PPVT_Age = mean(PPVT_Age, na.rm = TRUE),
    N_GFTA = sum(!is.na(GFTA_Age)),
    GFTA_Age = mean(GFTA_Age, na.rm = TRUE)) %>% 
  knitr::kable()
```

We can also compute summary statistics.

```{r}
df_kids %>% 
  select(Group, EVT_Age, EVT_Standard, PPVT_Standard, GFTA_Standard) %>% 
  # Convert to long format to compute summaries by group by score type
  tidyr::gather(Variable, Value, -Group) %>% 
  tidyr::drop_na(Value) %>% 
  group_by(Variable, Group) %>% 
  summarise(N_Values = n(), Mean = mean(Value), SD = sd(Value), 
            Min = min(Value), Max = max(Value)) %>% 
  # Round off decimals
  mutate_each_(funs(round), vars = vars(Mean, SD, Min, Max)) %>% 
  ungroup() %>% 
  knitr::kable()

df_kids %>% 
  count(Group, Maternal_Education) %>% 
  ungroup() %>% 
  knitr::kable()
```


Let's also get the children's database IDs from the backend database so that we
can pull their data from the eyetracking database.

```{r}
l2t_be <- l2t_connect(cnf_file, "backend")

df_cds <- tbl(l2t_be, "Child") %>% 
  left_join(tbl(l2t_be, "ChildStudy")) %>% 
  left_join(tbl(l2t_be, "Study")) %>% 
  select(Study, ShortResearchID, ChildStudyID, Birthdate) %>% 
  collect() %>% 
  # Keep just the kids in the analysis
  semi_join(df_kids)
```

This is a tedious step. We need to download the eyetracking data. First, let's
connect to the database and prepare some queries. 

```{r}
l2t_eyetracking <- l2t_connect(cnf_file, "eyetracking")

# We could do this with the prepared queries (q_BlocksByStudy, etc.), but the 
# query q_LooksByStudy takes forever to run. So we will select identify the
# blocks we want and get the trials and looks for just those blocks. That should
# be faster than start with all the data and narrowing down to the subset we
# want.

# Find the numbers of the blocks 
tbl_blocks <- tbl(l2t_eyetracking, "Blocks") %>% 
  filter(Block_Task == "RWL", 
         ChildStudyID %in% df_cds$ChildStudyID) %>% 
  select(BlockID, ChildStudyID, Block_Basename, 
         Block_DateTime, Block_Task, Block_Version, Block_Age)

# Get the attributes for these blocks
tbl_blocks_attrs <- tbl(l2t_eyetracking, "BlockAttributes") %>% 
  inner_join(tbl_blocks) %>% 
  select(ChildStudyID, BlockID, BlockAttribute_Name, BlockAttribute_Value)

# Get trial id numbers for these blocks
tbl_trials <- tbl(l2t_eyetracking, "Trials") %>% 
  inner_join(tbl_blocks) %>% 
  select(ChildStudyID, BlockID, TrialID, Trial_TrialNo)

# Get attributes of the trials
tbl_trials_attrs <- tbl(l2t_eyetracking, "TrialAttributes") %>% 
  inner_join(tbl_trials) %>% 
  select(ChildStudyID, BlockID, TrialID, 
         TrialAttribute_Name, TrialAttribute_Value)

# The big one. Get the looking data for these trials.
tbl_looks <- tbl(l2t_eyetracking, "Looks") %>% 
  inner_join(tbl_trials) %>% 
  select(ChildStudyID, BlockID, TrialID, Time, GazeByImageAOI, GazeByAOI)
```

Downloading the data takes forever, so I'm going set a flag called `refresh`.
When `refresh` is true, it will redownload the eyetracking data with those
queries. Otherwise, it will load the last copy that I saved.

```{r}
refresh <- FALSE

if (!refresh) {
  df_looks <- readr::read_csv(file.path(dir_here, "looks.csv"))
  df_blocks <- df_looks %>% 
    select(Study, ShortResearchID, Block_Age, 
           Block_Basename, Block_Dialect) %>% 
    distinct()
} else {
  df_blocks <- collect(tbl_blocks) %>% 
    left_join(df_cds) %>%
    group_by(ChildStudyID) %>%
    # We want one age per child, so use earliest. This might be dubious.
    mutate(Block_Age = min(Block_Age)) %>%
    ungroup()
     
  # Get the dialect
  df_blocks_attrs <- collect(tbl_blocks_attrs) %>% 
    # Pivot from long to wide so have the attributes we want
    tidyr::spread(BlockAttribute_Name, BlockAttribute_Value) %>% 
    select(ChildStudyID, BlockID, Block_Dialect = Dialect)
  
  # Add dialect to block info
  df_blocks <- df_blocks %>% 
    select(Study, ShortResearchID, BlockID, Block_Age, Block_Basename) %>% 
    left_join(df_blocks_attrs) 
  
  df_trials <- collect(tbl_trials)
  df_trials_attrs <- collect(tbl_trials_attrs, n = Inf)
  
  df_trials_attrs <- df_trials_attrs %>% 
    # Pivot from long to wide so have the attributes we want
    tidyr::spread(TrialAttribute_Name, TrialAttribute_Value) %>% 
    select(ChildStudyID, BlockID, TrialID, TargetImage,
           # Where they were looking the most during 0-250ms
           Bias_ImageAOI, 
           starts_with("Image"), starts_with("Stimulus"), starts_with("Word"))

  df_trials <- df_trials_attrs %>% 
    left_join(df_trials)
  
  df_looks <- collect(tbl_looks, n = Inf)
  
  df_looks <- df_blocks %>% 
    left_join(df_trials) %>% 
    left_join(df_looks) %>% 
    select(-BlockID, -ChildStudyID, -TrialID)
    
  readr::write_csv(df_looks, file.path(dir_here, "looks.csv"))
}
```

Let's kick out bad trials and blocks.

```{r}
df_blocks_to_drop <- df_looks %>% 
  filter(between(Time, 280, 1820)) %>% 
  lookr::AggregateLooks(Study + ShortResearchID + 
                          Block_Basename ~ GazeByImageAOI) %>% 
  as_data_frame() %>% 
  filter(PropNA > .5) %>% 
  select(Study:Block_Basename, PropNA) %>% 
  print(n = Inf)

df_trials_to_drop <- df_looks %>% 
  anti_join(df_blocks_to_drop) %>% 
  filter(between(Time, 280, 1820)) %>% 
  lookr::AggregateLooks(Study + ShortResearchID + Block_Basename + 
                          Trial_TrialNo ~ GazeByImageAOI) %>% 
  as_data_frame() %>% 
  filter(PropNA > .5) %>% 
  select(Study:Trial_TrialNo, PropNA) %>% 
  print()

df_looks <- df_looks %>% 
  anti_join(df_blocks_to_drop) %>% 
  anti_join(df_trials_to_drop)
```


Let's downsample into 50ms bins, and aggregate the number of looks.

```{r}
df_bins <- df_looks %>% 
  distinct(Time) %>%
  # Need a number of frames divisible three. Time 0 should be center of its bin
  filter(between(Time, -917, 1975)) %>% 
  arrange(Time) %>% 
  mutate(Bin = lookr::AssignBins(Time, bin_width = 3)) %>%
  group_by(Bin) %>% 
  # Round to nearest 50ms
  mutate(BinTime = Time %>% median() %>% round(-1)) %>% 
  ungroup()

df_binned <- df_looks %>% 
  inner_join(df_bins) %>%
  select(Study, ShortResearchID, Trial_TrialNo, 
         Time, BinTime, GazeByImageAOI, GazeByAOI) %>% 
  lookr::AggregateLooks(Study + ShortResearchID + BinTime ~ GazeByImageAOI) %>% 
  as_data_frame() %>% 
  mutate(Looks_Images = Target + Others,
         Prop_Target = Target / Looks_Images,
         Prop_PhonologicalFoil = PhonologicalFoil / Looks_Images,
         Prop_SemanticFoil = SemanticFoil / Looks_Images,
         Prop_Unrelated = Unrelated / Looks_Images)
df_binned
```

If we want to plot a growth curve for image type (target, semantic foil, etc.),
we need to reshape into a long format to have a Proportion column and an Image
type column.

```{r}
df_looks_to_aois <- df_binned %>% 
  select(Study, ShortResearchID, Time = BinTime, starts_with("Prop_")) %>% 
  tidyr::gather(AOI, Proportion, -Study, -ShortResearchID, -Time) %>% 
  mutate(AOI = AOI %>% 
           stringr::str_replace("Prop_", "") %>% 
           stringr::str_replace("Foil", "")) 

df_looks_to_aois$AOI <- factor(
  df_looks_to_aois$AOI, 
  levels = c("Target", "Phonological", "Semantic", "Unrelated"))
```

Do some spaghetti plots

```{r}
library(ggplot2)
df_looks_to_aois <- left_join(df_looks_to_aois, df_kids) %>% 
  mutate(LineGroup = interaction(Study, ShortResearchID, AOI))

curr_labs <- labs(
  x = "Time after target onset (ms.)", 
  y = "Proportion of looks", 
  color = "Image") 

p_theme <- theme_grey(base_size = 11) + 
  theme(legend.position = "bottom")

p1 <- ggplot(df_looks_to_aois) + 
  aes(x = Time, y = Proportion, color = AOI, group = LineGroup) + 
  geom_hline(yintercept = .25, size = 2, color = "white") + 
  geom_line() + 
  viridis::scale_color_viridis(discrete = TRUE, option = "inferno", end = .9) +
  facet_wrap("Group") +
  p_theme + curr_labs
p1  
```

Replace data-set in last plot with one with a narrow time window.

```{r}
df_looks_to_aois_window <- df_looks_to_aois %>% 
  filter(between(Time, 300, 1800))

p1 %+% df_looks_to_aois_window
```

Show average of each participant's lines.

```{r}
p2 <- ggplot(df_looks_to_aois) + 
  aes(x = Time, y = Proportion, color = AOI) + 
  geom_hline(yintercept = .25, size = 2, color = "white") + 
  stat_summary(fun.data = mean_se, geom = "pointrange") +
  facet_wrap("Group") +
  p_theme + curr_labs + 
  viridis::scale_color_viridis(discrete = TRUE, option = "inferno", end = .9)
p2  
```

```{r}
p2b <- ggplot(df_looks_to_aois_window) + 
  aes(x = Time, y = Proportion, color = AOI) + 
  geom_hline(yintercept = .25, size = 2, color = "white") + 
  stat_summary(fun.data = mean_se, geom = "pointrange") +
  facet_wrap("Group") +
  p_theme + curr_labs + 
  viridis::scale_color_viridis(discrete = TRUE, option = "inferno", end = .9)
p2b 
```

Actually, we don't need to facet them.

```{r}
p3 <- ggplot(df_looks_to_aois) + 
  aes(x = Time, y = Proportion, color = AOI, shape = Group) + 
  geom_hline(yintercept = .25, size = 2, color = "white") + 
  stat_summary(fun.data = mean_se, geom = "pointrange") +
  p_theme + curr_labs + 
  viridis::scale_color_viridis(discrete = TRUE, option = "inferno", end = .9)
p3
```

And zoom in.

```{r}
p4 <- ggplot(df_looks_to_aois_window) + 
  aes(x = Time, y = Proportion, color = AOI, shape = Group) + 
  geom_hline(yintercept = .25, size = 2, color = "white") + 
  stat_summary(fun.data = mean_se, geom = "pointrange") +
  p_theme + curr_labs + 
  viridis::scale_color_viridis(discrete = TRUE, option = "inferno", end = .9)
p4
```

Compare each mean of curve.

```{r}
p5 <- ggplot(df_looks_to_aois_window) + 
  aes(x = Time, y = Proportion, linetype = Group) + 
  geom_hline(yintercept = .25, size = 2, color = "white") + 
  stat_summary(fun.y = mean, geom = "line", size = 1.25) +
  facet_wrap("AOI") +
  p_theme + curr_labs
p5
```


Save a final data-set.

```{r}
df_ages <- df_blocks %>% 
  select(Study, ShortResearchID, Age = Block_Age) %>% 
  distinct()

df_subj_vars <- df_kids %>% 
  select(-Age) %>% 
  left_join(df_ages) %>% 
  select(Group, Study, ShortResearchID, Age, Female:GFTA_Standard) %>% 
  distinct() %>% 
  arrange(Group, Study, ShortResearchID)

df_long_props <- df_looks_to_aois_window %>% 
  left_join(df_subj_vars) %>% 
  select(Group, Study, ShortResearchID, Age:GFTA_Standard, 
         Time, AOI, Proportion) %>% 
  arrange(Group, Study, ShortResearchID, AOI, Time)

df_look_counts <- df_binned %>% 
  rename(LooksToTarget = Target, LooksToFoils = Others, 
         ProportionToTarget = Proportion, Time = BinTime) %>% 
  left_join(df_subj_vars) %>% 
  select(Group, Study, ShortResearchID, Age:GFTA_Standard, 
         Time, ProportionToTarget, LooksToTarget, LooksToFoils, 
         PhonologicalFoil, SemanticFoil, Unrelated) %>% 
  filter(between(Time, 300, 1800)) %>% 
  arrange(Group, Study, ShortResearchID)

readr::write_csv(df_subj_vars, file.path(dir_here, "subj_info.csv"))

readr::write_csv(
  df_long_props, 
  file.path(dir_here, "long_prop_looks_to_each_aoi.csv"))

readr::write_csv(
  df_look_counts, 
  file.path(dir_here, "wide_num_looks_to_each_aoi.csv"))
```


## Some modeling

Here is some code to do some light modeling. Read in the wide table of counts.

```{r}
library(lme4)
df <- readr::read_csv(file.path(dir_here, "wide_num_looks_to_each_aoi.csv"))

df$elog <- lookr::empirical_logit(df$LooksToTarget, df$LooksToFoils)
df$elog_wt <- lookr::empirical_logit_weight(df$LooksToTarget, df$LooksToFoils)

# For now let's ignore the fact that there are multiple growth curves for some
# children (e.g., children who contribute data in CochlearV1 and CochlearV2). We
# will pretend that those curves are from entirely different children, for the
# sake of model convergence.
df$ChildStudy <- paste0(df$Study, "_", df$ShortResearchID)

# The elogit model
m <- lmer(
  elog ~ poly(Time, 3) * Group + (poly(Time, 3) | ChildStudy),
  data = df,
  weights = 1 / elog_wt)
summary(m)

df$fitted <- fitted(m)

ggplot(df) + 
  aes(x = Time, y = elog, color = Group) + 
  stat_summary() + 
  stat_summary(aes(y = fitted), fun.y = mean, geom = "line")
```

