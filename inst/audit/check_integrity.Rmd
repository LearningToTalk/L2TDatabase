---
title: "Data Integrity Check"
author: "Tristan Mahr"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE, results = 'hide'}
library("knitr")
opts_chunk$set(echo = FALSE)
opts_chunk$set(collapse = TRUE, comment = "#>", message = FALSE)
opts_knit$set(root.dir = "../../")
```

```{r gather data, include = FALSE, message = FALSE, warning = FALSE, results = 'hide'}
library("L2TDatabase")
library("dplyr")
library("tidyr")
library("stringr")

# Load external dependencies
source("inst/paths.R")
source(paths$GetSiteInfo, chdir = TRUE)
source("inst/migrations/dates.R")

# Collect dates/scores
df_dates <- collect_dates(paths$score_dates, recursive = TRUE) %>% 
  filter(Study != "Dialect")

df_no_visits <- df_dates %>% 
  filter(Variable == "Visited") %>% 
  select(-Variable) %>% 
  rename(Visited = Value) %>% 
  filter(Visited == FALSE)

columns_in_dirt <- df_dates %>% 
  select(Variable) %>% 
  distinct

# Columns used the 2 sites x 3 timepoints spreadsheets
unique(df_dates$Variable)

# Get T1 scores for both sites. Function sourced via paths$GetSiteInfo
t1 <- get_study_info("TimePoint1")

t2 <- get_study_info("TimePoint2")

t3 <- get_study_info("TimePoint3")

ci1 <- get_study_info("CochlearV1")

ci2 <- get_study_info("CochlearV2")

ci_age <- get_study_info("CochlearMatching")

lt <- get_study_info("LateTalker")

medu <- get_study_info("Medu")

maybe_starts_with <- function(...) {
  vars <- starts_with(...)
  if (all(vars < 0)) numeric() else vars
}

maybe_matches <- function(...) {
  vars <- matches(...)
  if (all(vars < 0)) numeric() else vars
}

# Select necessary columns
get_scores_from_info <- function(df) {
  # Select and rename columns we want to compare
  df %>%
    select(ParticipantID = Participant_ID, Study, Source,
           # use maybe_starts_with so that we don't get an error when the column is not found
           EVT_Form = maybe_starts_with("EVT_Form"),
           EVT_Date = maybe_starts_with("EVT_COMPLETION"),
           EVT_Raw = maybe_starts_with("EVT_raw"),
           EVT_Standard = maybe_starts_with("EVT_standard"),
           EVT_GSV = maybe_starts_with("EVT_GSV"),
           PPVT_Form = maybe_starts_with("PPVT_Form"),
           PPVT_Date = maybe_starts_with("PPVT_COMPLETION"),
           PPVT_Raw = maybe_starts_with("PPVT_raw"),
           PPVT_Standard = maybe_starts_with("PPVT_standard"),
           PPVT_GSV = maybe_starts_with("PPVT_GSV"),
           FruitStroop_Score = maybe_starts_with("fruitstroop_time"),
           VerbalFluency_Score = maybe_starts_with("verbalfluency_raw"),
           VerbalFluency_AgeEquivalent = maybe_starts_with("verbalfluency_AE"),
           CTOPPElision_Raw = maybe_starts_with("CTOPP_Elision_raw"),
           CTOPPElision_Scaled = maybe_starts_with("CTOPP_Elision_scaled"),
           CTOPPBlending_Raw = maybe_starts_with("CTOPP_Blending_raw"),
           CTOPPBlending_Scaled = maybe_starts_with("CTOPP_Blending_scaled"),
           CTOPPMemory_Date = maybe_starts_with("CTOPP_MemoryforDigits_COMPLETION"),
           CTOPPMemory_Raw = maybe_starts_with("CTOPP_MemoryforDigits_raw"),
           CTOPPMemory_Scaled = maybe_starts_with("CTOPP_MemoryforDigits_scaled"),
           KBIT_Raw = maybe_starts_with("Kbit_nonverbalraw"),
           KBIT_Standard = maybe_starts_with("Kbit_nonverbalstandard"),
           GFTA_Date = maybe_starts_with("GFTA_COMPLETION_DATE"),
           DELV_Date = maybe_starts_with("DELV_Date"),
           DELV_LanguageVar_ColumnAScore = maybe_starts_with("DELV_LanguageVar_ColumnAScore"),
           DELV_LanguageVar_ColumnBScore = maybe_starts_with("DELV_LanguageVar_ColumnBScore"),
           DELV_LanguageVar = maybe_matches("DELV_LanguageVar$"),
           DELV_LanguageRisk_DiagnosticErrorScore = maybe_starts_with("DELV_LanguageRisk_DiagnosticErrorScore"),
           DELV_LanguageRisk = maybe_matches("DELV_LanguageRisk$")) %>%
    # Set dates to strings
    mutate_each(funs(format), maybe_matches("Date"))
}

# Combine scores in the UMN/UW spreadsheets, convert to long format
normalize_sheets <- . %>% 
  lapply(get_scores_from_info) %>% 
  Filter(function(x) nrow(x) != 0, .) %>% 
  bind_rows %>% 
  gather(Variable, Value, -ParticipantID, -Study, -Source)

# Normalize data from all three studies, combine to single study
df_info_long <- list(t1, t2, t3, ci1, ci2, ci_age, lt, medu) %>% 
  lapply(normalize_sheets) %>% 
  bind_rows

# Which columns need to be compared?
columns_in_info_sheets <- df_info_long %>% 
  select(Study, Variable) %>% 
  distinct

# Get the re-entered scores into the same format
df_dirt <- df_dates %>%
  select(-Site) %>%
  semi_join(columns_in_info_sheets) %>% 
  mutate(Source = "DIRT")
```

In Spring 2015, we had our data-entry team re-enter test scores gathered in our 
studies, so that we could find data-entry discrepancies. This script
compares the original to the re-entered scores.


## Studies under consideration

Data from the following studies are checked:

```{r}
unique(df_info_long$Study)
```


## Participant pool comparison

Do the same participants contribute scores in each set?

```{r}
df_both <- bind_rows(df_dirt, df_info_long)
df_sources_per_id <- df_both %>% 
  select(-Variable, -Value) %>% 
  distinct %>% 
  mutate(Found = TRUE) %>% 
  spread(Source, Found) %>% 
  arrange(Study, ParticipantID)
```

Participants in original score-set ("ParticipantInfo") *not in* the re-entered
score-set ("DIRT"):

```{r}
df_sources_per_id %>% 
  filter(is.na(DIRT)) %>% 
  anti_join(df_no_visits)
```

Participants in re-entered score-set ("DIRT") who visited the lab but are *not
in* the original score-set ("ParticipantInfo"). 

```{r}
df_sources_per_id %>% 
  filter(is.na(ParticipantInfo)) %>% 
  anti_join(df_no_visits)
```



## Value Comparison

We now compare the scores in each score-set. This check is only being performed
on participants in both score-sets.

```{r}
# Find which kids appear in both sources
df_children_to_compare <- df_sources_per_id %>% 
  filter(!is.na(DIRT), !is.na(ParticipantInfo)) %>% 
  select(Study, ParticipantID) %>% 
  distinct

df_comparing_scores <- df_both %>% 
  semi_join(df_children_to_compare) 

discrepancies <- df_comparing_scores %>%
  # select(-Study) %>%
  split(.$Variable) %>%
  lapply(readr::type_convert) %>%
  lapply(spread_, "Source", "Value") %>% 
  # lapply(function(df) select(df, DIRT)) %>%
  lapply(function(df) filter(df, DIRT %!==% ParticipantInfo)) %>%
  Filter(function(df) nrow(df) != 0, .) %>% 
  lapply(as.data.frame)
```

### Summary

This table lists all the fields that were checked and whether any discrepancies
were found in that field.

```{r}
columns_with_discrepancies <- discrepancies %>% names

columns_with_errors <- discrepancies %>% 
  lapply(. %>% select(Study, Variable)) %>% 
  bind_rows %>% 
  distinct %>% 
  arrange(Study, Variable) %>% 
  mutate(Passing = FALSE)

columns_in_info_sheets %>% 
  select(Study, Variable) %>% 
  distinct %>% 
  left_join(columns_with_errors) %>% 
  mutate(Passing = if_else(is.na(Passing), TRUE, Passing)) %>% 
  arrange(Study, Variable) %>% 
  mutate(Status = if_else(Passing, ":white_check_mark:", ":x:")) %>% 
  as.data.frame %>% 
  rename(` ` = Status) %>% 
  kable
```

### Details

These are all the mismatching values.

```{r}
discrepancies
```


### Unchecked fields

The following columns in DIRT were not checked because there is not a
matching column in the participant info spreadsheets

```{r}
columns_in_dirt_by_study <- df_dates %>% 
  select(Study, Variable) %>% 
  distinct

columns_in_dirt_by_study %>% 
  anti_join(columns_in_info_sheets) %>% 
  filter(Variable != "DOB", Variable != "Visited") %>% 
  as.data.frame %>% 
  mutate(Status = ":grey_question:") %>% 
  rename(` ` = Status) %>% 
  kable
```
